{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8831218",
   "metadata": {},
   "source": [
    "# Mlflow Expermintal Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72eb1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "413e2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/cleaned_test.csv')\n",
    "train_df = pd.read_csv('../data/cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755089c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "pipeline = joblib.load('../artifacts/preprocessing_pipeline.pkl')\n",
    "train_df = pipeline.transform(train_df)\n",
    "test_df = pipeline.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "911036ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                   Non-Null Count    Dtype  \n",
      "---  ------                   --------------    -----  \n",
      " 0   is_fraud                 1296675 non-null  int64  \n",
      " 1   last_hour_count          1296675 non-null  float64\n",
      " 2   last_hour_avg            1296675 non-null  float64\n",
      " 3   last_24h_count           1296675 non-null  float64\n",
      " 4   last_24h_avg             1296675 non-null  float64\n",
      " 5   dist                     1296675 non-null  float64\n",
      " 6   dist_diff                1296675 non-null  float64\n",
      " 7   D_Evening                1296675 non-null  bool   \n",
      " 8   D_Morning                1296675 non-null  bool   \n",
      " 9   D_Night                  1296675 non-null  bool   \n",
      " 10  category_food_dining     1296675 non-null  int32  \n",
      " 11  category_gas_transport   1296675 non-null  int32  \n",
      " 12  category_grocery_net     1296675 non-null  int32  \n",
      " 13  category_grocery_pos     1296675 non-null  int32  \n",
      " 14  category_health_fitness  1296675 non-null  int32  \n",
      " 15  category_home            1296675 non-null  int32  \n",
      " 16  category_kids_pets       1296675 non-null  int32  \n",
      " 17  category_misc_net        1296675 non-null  int32  \n",
      " 18  category_misc_pos        1296675 non-null  int32  \n",
      " 19  category_personal_care   1296675 non-null  int32  \n",
      " 20  category_shopping_net    1296675 non-null  int32  \n",
      " 21  category_shopping_pos    1296675 non-null  int32  \n",
      " 22  category_travel          1296675 non-null  int32  \n",
      "dtypes: bool(3), float64(6), int32(13), int64(1)\n",
      "memory usage: 137.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d41463d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('is_fraud', axis=1)\n",
    "y = train_df['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f9869e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f643b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7cdd7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/01 18:22:57 INFO mlflow.tracking.fluent: Experiment with name 'Anomaly Detection' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import os\n",
    "\n",
    "# Initialize MLflow Experiment\n",
    "mlflow.set_experiment(\"Anomaly Detection\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "os.environ[\"MLFLOW_ARTIFACT_ROOT\"] = \"file:///D:/final project/FruadDetection/github\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c81ba",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326189f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_supervised_model(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    \"\"\" Train, evaluate, and log a supervised model (Random Forest) in MLflow \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name): \n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "        # AUC Calculation\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "        # Log metrics & model in MLflow\n",
    "        mlflow.log_params(model.get_params())  \n",
    "        mlflow.log_metrics({\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1, \"kappa\": kappa, \"roc_auc\": auc})\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "        print(f\"\\nüöÄ {model_name} Evaluation Completed\\n\")\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"Precision:\", prec)\n",
    "        print(\"Recall:\", rec)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        print(\"Cohen Kappa Score:\", kappa)\n",
    "        print(\"ROC-AUC Score:\", auc)\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a432cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   45.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "2025/05/01 18:23:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Random Forest Evaluation Completed\n",
      "\n",
      "Accuracy: 0.9983701925177955\n",
      "Precision: 0.9303191489361702\n",
      "Recall: 0.7766429840142096\n",
      "F1 Score: 0.8465634075508228\n",
      "Cohen Kappa Score: 0.8457508281499154\n",
      "ROC-AUC Score: 0.9941677275265799\n",
      "Confusion Matrix:\n",
      " [[386620    131]\n",
      " [   503   1749]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/01 18:23:58 INFO mlflow.tracking._tracking_service.client: üèÉ View run Random Forest at: http://localhost:5000/#/experiments/554229172752345466/runs/4888726a13d74bbc9d6cd1b806909ed2.\n",
      "2025/05/01 18:23:58 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/554229172752345466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    386751\n",
      "           1       0.93      0.78      0.85      2252\n",
      "\n",
      "    accuracy                           1.00    389003\n",
      "   macro avg       0.96      0.89      0.92    389003\n",
      "weighted avg       1.00      1.00      1.00    389003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "rf_clf = RandomForestClassifier(n_estimators=50, max_depth=20, random_state=345, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_supervised_model(rf_clf, \"Random Forest\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f340f9",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffaddf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_AnomalyDetection_model(model, model_name, X_train, X_test, y_test):\n",
    "    \"\"\" Train, evaluate, and log an unsupervised model (Isolation Forest) in MLflow \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name): \n",
    "        \n",
    "        # Train Isolation Forest (Only X, no Y)\n",
    "        model.fit(X_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = [1 if x == -1 else 0 for x in y_pred]  # Convert anomalies (-1) to fraud (1)\n",
    "\n",
    "        # Confusion Matrix & Classification Report\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        # Compute ROC-AUC using decision_function\n",
    "        y_prob = model.decision_function(X_test)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "        # Calculate Additional Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "        # Log metrics & model in MLflow\n",
    "        mlflow.log_params(model.get_params())  \n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1_score\": f1,\n",
    "            \"cohen_kappa\": kappa,\n",
    "            \"roc_auc\": auc\n",
    "        })\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "        print(f\"\\nüî• {model_name} Evaluation Completed\\n\")\n",
    "        print(\"Accuracy:\", acc)\n",
    "        print(\"Precision:\", prec)\n",
    "        print(\"Recall:\", rec)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        print(\"Cohen Kappa Score:\", kappa)\n",
    "        print(\"ROC-AUC Score:\", auc)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ddb6a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    0.9s remaining:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.2s\n",
      "2025/05/01 18:26:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/01 18:26:50 INFO mlflow.tracking._tracking_service.client: üèÉ View run Isolation Forest at: http://localhost:5000/#/experiments/554229172752345466/runs/346cf469c288450ba608f7552d05b9b0.\n",
      "2025/05/01 18:26:50 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/554229172752345466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî• Isolation Forest Evaluation Completed\n",
      "\n",
      "Accuracy: 0.972912805299702\n",
      "Precision: 0.13441002559350454\n",
      "Recall: 0.6762877442273535\n",
      "F1 Score: 0.2242509018626224\n",
      "Cohen Kappa Score: 0.21668511065723084\n",
      "ROC-AUC Score: 0.06892917509681568\n",
      "Confusion Matrix:\n",
      " [[376943   9808]\n",
      " [   729   1523]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    386751\n",
      "           1       0.13      0.68      0.22      2252\n",
      "\n",
      "    accuracy                           0.97    389003\n",
      "   macro avg       0.57      0.83      0.61    389003\n",
      "weighted avg       0.99      0.97      0.98    389003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "iso_forest = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_AnomalyDetection_model(iso_forest, \"Isolation Forest\", X_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed3a3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Isolation Forest'.\n",
      "2025/05/01 18:39:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Isolation Forest, version 1\n",
      "Created version '1' of model 'Isolation Forest'.\n",
      "2025/05/01 18:39:17 INFO mlflow.tracking._tracking_service.client: üèÉ View run Isolation Forest at: http://localhost:5000/#/experiments/554229172752345466/runs/346cf469c288450ba608f7552d05b9b0.\n",
      "2025/05/01 18:39:17 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/554229172752345466.\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "model_name = 'Isolation Forest'\n",
    "run_id=input('Please type RunID')\n",
    "model_uri = f'runs:/{run_id}/model'\n",
    "\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "client = MlflowClient()\n",
    "run = client.get_run(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594eb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred = [1 if x == -1 else 0 for x in y_pred]\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dagshub setup\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='learnpythonlanguage', repo_name='mlflow_dagshub_demo', mlflow=True)\n",
    "\n",
    "# # Ideally you will not require following 4 lines if you have started fresh and do not have any previous dagshub credentials on your computer\n",
    "# import os\n",
    "# os.environ['MLFLOW_TRACKING_USERNAME'] = 'your user name' # 'learnpythonlanguage'\n",
    "# os.environ['MLFLOW_TRACKING_PASSWORD'] = 'your password' # \n",
    "# os.environ['MLFLOW_TRACKING_URI'] = 'your dagshub unique uri' # https://dagshub.com/learnpythonlanguage/mlflow_dagshub_demo.mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a369cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
